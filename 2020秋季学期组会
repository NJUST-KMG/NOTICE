每周日晚周期性会议ID：578 6499 0634

2020.11.29（周日）晚19:00
魏：论文：Learn, Imagine and Create: Text-to-Image
倪：论文：Learning to learn from noisy labeled data

2020.11.22（周日）晚19：00
王：论文：A Survey on Knowledge Graphs Representation Acquisition and Applications
郭：论文：Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss
       Q1.数据不平衡的分类：step imbalance和long-tailed imbalance的区别？
             long-tailed imbalance指的是类的数据数量呈现长尾分布，即不断降低的一条曲线。
             step imbalance指的是频繁类和少数类的数据量不同，但两个频繁类之间和两个少数类之间的数据量相同。
             两者都是自然界中普遍存在的数据不平衡现象。

2020.11.15（周日）晚19：00
张：论文：Does William Shakespeare REALLY Write Hamlet?Knowledge Representation
       Learning with Confidence
       Q1:关于论文中作者提出的路径是如何得到的？
              作者通过枚举的方式得到的路径集合
       Q2:Relation Path Reliability是如何体现可靠地？
              作者采用资源分配的思想，给一个head分配固定数量的资源，假设为1，其中e1∈Eii1(·,e)表示关系r对应的前驱实体，|Ei(e1, ·)|表示关系r前驱
              实体中相同关系的后继节点数的倒数，Rp(e)表示实体分配的资源，即一个节点获得的资源由前驱节点分配给他的资源总和，而前驱节点分配的资源
              由Rp(e1)/|Ei(e1, ·)|得到；例如求节点m的分配资源，n为它的一个前驱，三元组（n,r,m），n在相同关系下的尾实体可能是多个记为x，则|Ei(e1, ·)|
              =x；通过这样如果这条路径分配的资源越多，说明这条关系路径越可靠；
鲍：论文：Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks

2020.11.8（周日）晚19:00
傅：论文：application of autoencoder in novelty detection：Latent Space Autoregression for Novelty Detection
             ROBUST SUBSPACE RECOVERY LAYER FOR UNSUPERVISED ANOMALY DETECTION
             NOVELTY DETECTION WITH RECONSTRUCTION ALONG PROJECTION PATHWAY
魏：论文：Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations

2020.11.1（周日）晚19：00
倪：论文：Learning from Noisy Labels with Deep Neural Networks: A Survey
       Q1：Roubust function具体应该怎么写？
           以GCE为例，它综合了MAC与CCE的优点
           令于是它在q->0时趋向于CCE，在q->1时趋向于MAE

       Q2：用于预测噪声类型和预测噪声的模块具体是怎么工作的？
           用有干净标签的数据与它的噪声标签放入神经网络训练，训练出两个模型。
           一个预测数据是无噪声(noise free)以及有噪声的噪声种类(random,cofusing)；另一个模型预测它的标签。两者综合得到它的最终预计标签。

       Q3：Loss correction中的label transition matrix T是如何定的？
           T如果有的话可以直接给模型用来训练；没有的时候需要先训练出一个T
傅：论文：application of autoencoder in novelty detection：Latent Space Autoregression for Novelty Detection
             ROBUST SUBSPACE RECOVERY LAYER FOR UNSUPERVISED ANOMALY DETECTION
             NOVELTY DETECTION WITH RECONSTRUCTION ALONG PROJECTION PATHWAY

2020.10.24（周日）晚19：00
张：GCN论文：SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS
      Q1:在GCN论文中有关作者的实验结果中GCN (rand. splits)的疑问？
            作者在这里交叉验证他们的模型在10个随机绘制的相同大小的数据集分割上的性能。
魏：论文：Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations
郭：论文：Image Classification with Deep Learning in the Presence of Noisy Labels: A Survey
      Q1:Random noise和Y-dependent random noise有什么区别?
        Y-dependent random noise变化到其他类的概率是随机的，而变到自身true class的概率不随机，没有找到相关资料，我推断是先给定这个概率，然后变到其他类的概率再随机，因此这
